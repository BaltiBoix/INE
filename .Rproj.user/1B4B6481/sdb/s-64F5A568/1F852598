{
    "contents" : "---\ntitle: \"Practical Machine Learning Project Assignment\"\nauthor: \"Balti Boix\"\ndate: \"7 de noviembre de 2015\"\noutput: html_document\n---\n\n###The Weight Lifting Exercises Dataset Description\n\nThis human activity recognition research has focused on \"how (well)\" an activity was performed by the wearer. \n\nSix young health participants were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions: \n\n      exactly according to the specification (Class A), \n      throwing the elbows to the front (Class B), \n      lifting the dumbbell only halfway (Class C), \n      lowering the dumbbell only halfway (Class D) and \n      throwing the hips to the front (Class E).\n\nClass A corresponds to the specified execution of the exercise, while the other 4 classes correspond to common mistakes.\n\n###Source\n\nQualitative Activity Recognition of Weight Lifting Exercises\nVelloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th Augmented Human (AH) International Conference in cooperation with ACM SIGCHI (Augmented Human'13) . Stuttgart, Germany: ACM SIGCHI, 2013. \nCited by 15 (Google Scholar)\n\nRead more: \n      http://groupware.les.inf.puc-rio.br/work.jsf?p1=11201#ixzz3qpR558zc\n      http://groupware.les.inf.puc-rio.br/har\n\n###Goal\n\nThe goal of your project is to predict the manner in which they did the exercise. This is the \"classe\" variable in the training set. You may use any of the other variables to predict with. You should create a report describing how you built your model, how you used cross validation, what you think the expected out of sample error is, and why you made the choices you did. You will also use your prediction model to predict 20 different test cases. \n\n###Discussion of results\nI have not been able to find a description of the data set variables on the Internet. I can guess that it consist in time series grouped in windows that should be analized together. But as the test data correspond to independent rows I have decided to consider the same in the training set. A summary of the training data is on the appendix. \n\nIf we want to find a model that can be used to check if a person is doing his/her exercises correctly seems clear that variables like user_name or date should not be used. As it seems that the test data has been extracted from the time series these variables are very significant in the models. To show it **fit1** model uses only this type of information (cols 2:7) and gets a perfect match!\n\nIn models **fit** and **fit0** the cols that are basically NA's have been removed. Cols 2:7 are also removed. Cross-Validation with k=3 have been used as resampling method. The default resampling method takes too long to solve in my PC. In Fit0 the data set is not preprocessed. In **fit1** preProcess=\"pca\" have been used.\n\nAt the three fits a perfect match is attained on the training data. The estimated out-of-sample error is very low.\n\nThe prediction over the test data give the same results except for **fit** in the third row (incorrect in submission part of the assigment and been correct the result with **fit0** and **fit1**).\n\nA facet plot of the 20 most important variable of **fit0** are shown on the appendix\n\n\n####Loading and Processing the Raw Data\n\nThe training and test csv files are downloaded from the Course Web into R working directory.\nFrom there are read directly into Data frames using the file header as column names.\n\n```{r cache=TRUE}\ndownload.file(\"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv\", \"pml-training.csv\")\ndownload.file(\"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv\", \"pml-testing.csv\")\nOrigtraindf<-read.table(\"pml-training.csv\", sep = \",\", header = TRUE, na.strings = c(\"NA\", \"\", \"#DIV/0!\"))\nOrigtestdf<-read.table(\"pml-testing.csv\", sep = \",\", header = TRUE, na.strings = c(\"NA\", \"\", \"#DIV/0!\"))\n```\n\nR Packages used for analysis and plotting are loaded if required.\nThe number of rows and columns are shown.\n\n```{r message=FALSE, warning=FALSE, tidy=TRUE}\nrequire(dplyr, quietly = TRUE)\nrequire(ggplot2, quietly = TRUE)\nrequire(caret, quietly = TRUE)\nrequire(rpart, quietly = TRUE)\nrequire(randomForest, quietly = TRUE)\nrequire(gbm, quietly = TRUE)\nrequire(foreach, quietly = TRUE)\nrequire(doParallel, quietly = TRUE)\nrequire(tidyr, quietly = TRUE)\n\nif(file.exists(\"my_fit.rda\") & !exists(\"fit\")) load(\"my_fit.rda\")\nif(file.exists(\"my_fit0.rda\") & !exists(\"fit0\")) load(\"my_fit0.rda\")\nif(file.exists(\"my_fit1.rda\") & !exists(\"fit1\")) load(\"my_fit1.rda\")\n\ndata.frame(dim(Origtraindf), dim(Origtestdf))\n```\n\nFirst obvious cols like X (equivalent a number of row), user name, time_stamps and windows are removed.  \nThen the cols (variables) that have more than 80% of values different from NA are determined and selected. \nOr what is the same, the cols with more tan 80% of NA's are removed.\n\n```{r message=FALSE, warning=FALSE}\nfiltervars<-names(Origtraindf)\nfiltervars<-filtervars[8:length(filtervars)]\ntraindf<-select(Origtraindf, one_of(filtervars))\nfiltervars<-names(traindf[, colSums(!is.na(traindf)) > 0.8*nrow(traindf)])\ntraindf<-select(traindf, one_of(filtervars))\n```\n\nModels **fit**, **fit0** and **fit1** are generated and the statistics are shown using the function confusionMatrix \n\n```{r message=FALSE, warning=FALSE}\nif(!exists(\"fit\")) {\n      fit<-train(classe ~ ., method= \"rf\", trControl = trainControl(method = \"cv\", number = 3), \n                 preProcess=\"pca\", data = traindf)\n      save(fit, file=\"my_fit.rda\")}\n\nconfusionMatrix(traindf$classe, predict(fit, Origtraindf))\n\nif(!exists(\"fit0\")) {\n      fit0<-train(classe ~ ., method= \"rf\", trControl = trainControl(method = \"cv\", number = 3), \n                 data = traindf)\n      save(fit0, file=\"my_fit0.rda\")}\n\nconfusionMatrix(traindf$classe, predict(fit0, Origtraindf))\n\nif(!exists(\"fit1\")) {\n      traindf<- Origtraindf[,2:7]\n      fit1<-train(classe ~ ., method= \"rf\", trControl = trainControl(method = \"cv\", number = 3), \n                 data = traindf)\n      save(fit1, file=\"my_fit1.rda\")}\n\nconfusionMatrix(traindf$classe, predict(fit1, Origtraindf))\n```\n\nFrom every model we extract the accuracy of the three folders used for resampling.\nThe out-of-sample error is estimated from the mean accuracy.\n\n```{r message=FALSE, warning=FALSE}\naccufit<-data.frame(Fit=fit$resample$Accuracy, Fit0=fit0$resample$Accuracy, \n                    Fit1=fit1$resample$Accuracy)\naccufit\nsummarize(accufit, oos=round(1-mean(Fit),4), oos0=round(1-mean(Fit0),4), \n          oos1=round(1-mean(Fit1),4))\n```\n\nApplying the models to the test data and grouped and shown in the **resdf** data frame.\n\n```{r message=FALSE, warning=FALSE}\nresdf<-data.frame(classe0=predict(fit0, Origtestdf), classe=predict(fit, Origtestdf), classe1=predict(fit1, Origtestdf))\nresdf\n```\n\nThe files for the submission assignment are printed with the function suggested in the Coursera project page.\n\n```{r message=FALSE, warning=FALSE}\npml_write_files = function(x){\n  n = length(x)\n  for(i in 1:n){\n    filename = paste0(\"problem_id_\",i,\".txt\")\n    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)\n  }\n}\n\npml_write_files(as.vector(resdf$classe0))\n```\n\n### Appendix\n\nA summary of the training data set is presented.\n\n```{r message=FALSE, warning=FALSE}\nsummary(Origtraindf)\n```\n\nA facet plot of the 20 most important variable of **fit0**\n\n```{r message=FALSE, warning=FALSE}\nvi<-varImp(fit0)\ndf<-data.frame(name=rownames(vi$importance), imp=vi$importance$Overall)\ndf<-arrange(df, -imp)\nplotdf<-select(Origtraindf, one_of(c(\"classe\", as.character(df$name[1:20]))))\nplotdf<-gather(plotdf, key=clave, value=valor, -classe)\nplotdf$clave<-factor(plotdf$clave, levels=as.character(df$name[1:20]))\np<-ggplot(plotdf, aes(x=classe, y=valor, fill=classe)) \np<-p + geom_boxplot()\np<-p + facet_wrap(~ clave, scales=\"free_y\", ncol=4)\nprint(p)\n```\n\n",
    "created" : 1448191584825.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2567532574",
    "id" : "1F852598",
    "lastKnownWriteTime" : 1447886367,
    "path" : "~/Coursera/predmachlearn/predmachlearn.Rmd",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "type" : "r_markdown"
}